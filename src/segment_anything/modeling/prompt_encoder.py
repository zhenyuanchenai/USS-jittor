import numpy as np
import jittor as jt
from jittor import nn
from jittor import init
import numpy as np
from typing import Any, Optional, Tuple, Type
from .common import LayerNorm2d


class PromptEncoder(nn.Module):
    def __init__(
        self,
        embed_dim: int,
        image_embedding_size: Tuple[int, int],
        input_image_size: Tuple[int, int],
        mask_in_chans: int,
        activation: Type[jt.nn.Module] = nn.GELU,
    ) -> None:
        
        super().__init__()
        self.embed_dim = embed_dim
        self.input_image_size = input_image_size
        self.image_embedding_size = image_embedding_size
        self.pe_layer = PositionEmbeddingRandom(embed_dim // 2)

        self.num_point_embeddings: int = 4  # pos/neg point + 2 box corners
        point_embeddings = [nn.Embedding(1, embed_dim) for i in range(self.num_point_embeddings)]
        self.point_embeddings = nn.ModuleList(point_embeddings)
        self.not_a_point_embed = nn.Embedding(1, embed_dim)

        self.mask_input_size = (4 * image_embedding_size[0], 4 * image_embedding_size[1])
        self.mask_downscaling = nn.Sequential(
            nn.Conv(1, mask_in_chans // 4, kernel_size=2, stride=2),
            LayerNorm2d(mask_in_chans // 4),
            activation(),
            nn.Conv(mask_in_chans // 4, mask_in_chans, kernel_size=2, stride=2),
            LayerNorm2d(mask_in_chans),
            activation(),
            nn.Conv(mask_in_chans, embed_dim, kernel_size=1),
        )
        self.no_mask_embed = nn.Embedding(1, embed_dim)

    def get_dense_pe(self) -> jt.Var:

        return self.pe_layer(self.image_embedding_size).unsqueeze(0)

    def _embed_points(
        self,
        points: jt.Var,
        labels: jt.Var,
        pad: bool,
    ) -> jt.Var:
        """Embeds point prompts."""
        points = points + 0.5  # Shift to center of pixel
        if pad:
            padding_point = jt.zeros((points.shape[0], 1, 2))
            padding_label = -jt.ones((labels.shape[0], 1))
            points = jt.concat([points, padding_point], dim=1)
            labels = jt.concat([labels, padding_label], dim=1)
        point_embedding = self.pe_layer.forward_with_coords(points, self.input_image_size)
        point_embedding[labels == -1] = 0.0
        point_embedding[labels == -1] += self.not_a_point_embed.weight
        point_embedding[labels == 0] += self.point_embeddings[0].weight
        point_embedding[labels == 1] += self.point_embeddings[1].weight
        return point_embedding

    def _embed_boxes(self, boxes: jt.Var) -> jt.Var:
        """Embeds box prompts."""
        boxes = boxes + 0.5  # Shift to center of pixel
        coords = boxes.reshape(-1, 2, 2)
        corner_embedding = self.pe_layer.forward_with_coords(coords, self.input_image_size)
        corner_embedding[:, 0, :] += self.point_embeddings[2].weight
        corner_embedding[:, 1, :] += self.point_embeddings[3].weight
        return corner_embedding

    def _embed_masks(self, masks: jt.Var) -> jt.Var:
        """Embeds mask inputs."""
        mask_embedding = self.mask_downscaling(masks)
        return mask_embedding

    def _get_batch_size(
        self,
        points: Optional[Tuple[jt.Var, jt.Var]],
        boxes: Optional[jt.Var],
        masks: Optional[jt.Var],
    ) -> int:
        """
        Gets the batch size of the output given the batch size of the input prompts.
        """
        if points is not None:
            return points[0].shape[0]
        elif boxes is not None:
            return boxes.shape[0]
        elif masks is not None:
            return masks.shape[0]
        else:
            return 1
    
    def _get_device(self):
        if jt.flags.use_cuda:
            return 'cuda'
        else:
            return 'cpu'

    def execute(
        self,
        points: Optional[Tuple[jt.Var, jt.Var]],
        boxes: Optional[jt.Var],
        masks: Optional[jt.Var],
    ) -> Tuple[jt.Var, jt.Var]:

        bs = self._get_batch_size(points, boxes, masks)
        sparse_embeddings = jt.empty((bs, 0, self.embed_dim))
        if points is not None:
            coords, labels = points
            point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
            sparse_embeddings = jt.concat([sparse_embeddings, point_embeddings], dim=1)
        if boxes is not None:
            box_embeddings = self._embed_boxes(boxes)
            #box_embeddings = box_embeddings.unsqueeze(1)
            sparse_embeddings = jt.concat([sparse_embeddings, box_embeddings], dim=1)

        if masks is not None:
            dense_embeddings = self._embed_masks(masks)
        else:
            dense_embeddings = jt.reshape(self.no_mask_embed.weight, (1, -1, 1, 1)).expand(
                (bs, -1, self.image_embedding_size[0], self.image_embedding_size[1])
            )

        return sparse_embeddings, dense_embeddings
    
class PositionEmbeddingRandom(nn.Module):
    """
    Positional encoding using random spatial frequencies.
    """

    def __init__(self, num_pos_feats: int = 64, scale: Optional[float] = None):
        super().__init__()
        if scale is None or scale <= 0.0:
            scale = 1.0
        self.positional_encoding_gaussian_matrix = init.gauss((2, num_pos_feats), "float32") * scale

    def _pe_encoding(self, coords: jt.Var) -> jt.Var:
        """Positionally encode points that are normalized to [0,1]."""
        # assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape
        coords = 2 * coords - 1
        coords = coords.matmul(self.positional_encoding_gaussian_matrix)
        coords = 2 * np.pi * coords
        # outputs d_1 x ... x d_n x C shape
        return jt.concat([jt.sin(coords), jt.cos(coords)], dim=-1)

    def execute(self, size: Tuple[int, int]) -> jt.Var:
        """Generate positional encoding for a grid of the specified size."""
        h, w = size
        grid = jt.ones((h, w), dtype='float32')
        y_embed = jt.cumsum(grid, dim=0) - 0.5
        x_embed = jt.cumsum(grid, dim=1) - 0.5
        y_embed = y_embed / h
        x_embed = x_embed / w

        pe = self._pe_encoding(jt.stack([x_embed, y_embed], dim=-1))
        return pe.permute(2, 0, 1)  # C x H x W

    def forward_with_coords(
        self, coords_input: jt.Var, image_size: Tuple[int, int]
    ) -> jt.Var:
        """Positionally encode points that are not normalized to [0,1]."""
        coords = coords_input.clone()
        coords[:, :, 0] = coords[:, :, 0] / image_size[1]
        coords[:, :, 1] = coords[:, :, 1] / image_size[0]
        return self._pe_encoding(coords.cast('float32'))  # B x N x C